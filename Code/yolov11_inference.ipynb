{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9d7700-ac1b-4876-959c-6ab7d04047ee",
   "metadata": {},
   "source": [
    "## Load YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7631a09-7494-463a-959c-89dcdafb423c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# Loading trained YOLO model\n",
    "model = YOLO(\"/data_vault/hexai/OAICartilage/runs/detect/SagittalKneeJoint/weights/best.pt\")\n",
    "\n",
    "# Run prediction and save cropped images\n",
    "results = model.predict(\"/data_vault/hexai/OAICartilage/Image\", save=True, save_crop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713770ca-10ef-4f47-a1b4-84b34d4749be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Extracting Bounding Box Coordinates from YOLO Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d79c2-a769-48fb-a46a-191f8c0ea070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract Bounding Boxes and Save\n",
    "import os\n",
    "import re\n",
    "bbox_dict = {}  \n",
    "for result in results:\n",
    "    image_name = os.path.basename(result.path)  # Get image filename\n",
    "    \n",
    "    # ID + slice number as string\n",
    "    match = re.match(r\"(\\d+_\\d+_\\d+)_slice_(\\d+)\", image_name)\n",
    "    if not match:\n",
    "        print(f\"Unrecognized filename format: {image_name}\")\n",
    "        continue  # Skip unrecognized filenames\n",
    "\n",
    "    study_id, slice_num_str = match.groups() \n",
    "\n",
    "    boxes = result.boxes.xyxy.cpu().numpy()  # Extract bounding box coordinates (x1, y1, x2, y2)\n",
    "\n",
    "    # Print progress for each image processed\n",
    "    print(f\"Processing {image_name} (ID: {study_id}, Slice: {slice_num_str})\")\n",
    "\n",
    "    # Store bounding boxes in bbox_dict, keeping slice_num_str as string\n",
    "    if study_id not in bbox_dict:\n",
    "        bbox_dict[study_id] = {}\n",
    "    \n",
    "    # Store boxes under study ID -> slice number as string\n",
    "    bbox_dict[study_id][slice_num_str] = boxes\n",
    "\n",
    "    # Print the bounding boxes for this image\n",
    "    if len(boxes) == 0:\n",
    "        print(\"  No detections\")\n",
    "    else:\n",
    "        for idx, box in enumerate(boxes):\n",
    "            print(f\" Bounding box {idx+1}: {box}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e77503-3e3c-4dd4-9b35-ca3e30f569f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bounding boxes to a .pkl file\n",
    "bbox_save_path = \"/data_vault/hexai/OAICartilage/bbox_dict.pkl\"\n",
    "with open(bbox_save_path, \"wb\") as f:\n",
    "    pickle.dump(bbox_dict, f)\n",
    "\n",
    "print(f\"Bounding boxes saved successfully to {bbox_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836afc9d-12a4-44b9-bc5e-b330c5f6ceac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Crop Images based on Bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b9fc07-7053-40a1-896b-74d6b628e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop image based on bbox\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "# Paths\n",
    "image_folder = \"/data_vault/hexai/OAICartilage/Image\"  # Original images\n",
    "bbox_pickle_path = \"/data_vault/hexai/OAICartilage/bbox_dict.pkl\"\n",
    "output_crop_folder = \"/data_vault/hexai/OAICartilage/image_manual_crops\"\n",
    "os.makedirs(output_crop_folder, exist_ok=True)\n",
    "\n",
    "# Manual cropping\n",
    "for study_id, slices in bbox_dict.items():\n",
    "    for slice_num_str, bboxes in slices.items():\n",
    "        image_filename = f\"{study_id}_slice_{slice_num_str}.jpg\"\n",
    "        image_path = os.path.join(image_folder, image_filename)\n",
    "\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image not found: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        for idx, (x1, y1, x2, y2) in enumerate(bboxes):\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "            cropped_image = image.crop((x1, y1, x2, y2))\n",
    "\n",
    "            crop_filename = f\"{study_id}_slice_{slice_num_str}.jpg\"\n",
    "            crop_path = os.path.join(output_crop_folder, crop_filename)\n",
    "            cropped_image.save(crop_path)\n",
    "\n",
    "print(\"âœ… Manual cropping complete using bounding box data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457680a-5d36-4da6-9d29-8e95a0de1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading bbox\n",
    "import pickle\n",
    "\n",
    "# Load bbox_dict from a pickle file\n",
    "with open(\"/data_vault/hexai/OAICartilage/bbox_dict.pkl\", \"rb\") as f:\n",
    "    bbox_dict = pickle.load(f)\n",
    "\n",
    "print(\"âœ… Loaded bbox_dict successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c416d10e-e906-40fc-a78a-6b7ab52a8ae4",
   "metadata": {},
   "source": [
    "## SIMPLE ITK LIBRARY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b353227-7de9-417a-abe9-d7c446d295fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "annotation_folder = \"/data_vault/hexai/OAICartilage/Annotations copy\"\n",
    "output_folder = \"/data_vault/hexai/OAICartilage/cropped_annotations_simpleitk_v2\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# Process each annotation file \n",
    "for study_id, slices in bbox_dict.items():\n",
    "    input_path = os.path.join(annotation_folder, f\"{study_id}.nii.gz\")\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Annotation not found: {input_path}\")\n",
    "        continue\n",
    "\n",
    "    # Read ITK-SNAP NIfTI image \n",
    "    img = sitk.ReadImage(input_path)\n",
    "    img_np = sitk.GetArrayFromImage(img)  # Shape\n",
    "\n",
    "    # Store spatial metadata\n",
    "    spacing = img.GetSpacing()\n",
    "    origin = img.GetOrigin()\n",
    "    direction = img.GetDirection()\n",
    "\n",
    "    print(f\"Processing {study_id} | Volume shape: {img_np.shape}\")\n",
    "\n",
    "    study_output_dir = os.path.join(output_folder, study_id)\n",
    "    os.makedirs(study_output_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through annotated slices\n",
    "    for slice_num_str, bboxes in slices.items():\n",
    "        slice_index = int(slice_num_str) - 1  # YOLO slices are 1-based\n",
    "\n",
    "        if slice_index < 0 or slice_index >= img_np.shape[0]:\n",
    "            print(f\"Skipping slice {slice_num_str} (out of bounds)\")\n",
    "            continue\n",
    "\n",
    "        slice_2d = img_np[slice_index, :, :]  # [Y, X]\n",
    "\n",
    "        for idx, (x1, y1, x2, y2) in enumerate(bboxes):\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "\n",
    "            # Ensure bounding box is valid\n",
    "            if (\n",
    "                x1 < 0 or y1 < 0 or\n",
    "                x2 > slice_2d.shape[1] or y2 > slice_2d.shape[0]\n",
    "            ):\n",
    "                print(f\"Skipping invalid crop for {study_id} slice {slice_num_str}\")\n",
    "                continue\n",
    "\n",
    "            # Crop annotation from slice\n",
    "            cropped_np = slice_2d[y1:y2, x1:x2]\n",
    "            cropped_3d = np.expand_dims(cropped_np, axis=0)  # [1, Y, X]\n",
    "\n",
    "            cropped_img = sitk.GetImageFromArray(cropped_3d)\n",
    "            cropped_img.SetSpacing(spacing)\n",
    "            cropped_img.SetOrigin(origin)\n",
    "            cropped_img.SetDirection(direction)\n",
    "\n",
    "            output_path = os.path.join(\n",
    "                study_output_dir,\n",
    "                f\"{study_id}_slice_{int(slice_num_str):03d}_crop{idx}.nii.gz\"\n",
    "            )\n",
    "            sitk.WriteImage(cropped_img, output_path)\n",
    "            print(f\"Saved: {output_path}\")\n",
    "            # Save NumPy version\n",
    "            \n",
    "            numpy_output_dir = \"/data_vault/hexai/OAICartilage/cropped_annotations_numpy\"\n",
    "            os.makedirs(os.path.join(numpy_output_dir, study_id), exist_ok=True)\n",
    "            \n",
    "            np_save_path = os.path.join(\n",
    "                numpy_output_dir, study_id,\n",
    "                f\"{study_id}_slice_{int(slice_num_str):03d}.npy\"\n",
    "            )\n",
    "            np.save(np_save_path, cropped_np)\n",
    "            print(f\"Saved NumPy: {np_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f864c392-c7e0-4dde-84d8-746713f25afb",
   "metadata": {},
   "source": [
    "## Dimension Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738fc2a-0ebe-4f82-a74c-48530f6ece56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Load any YOLO-cropped image\n",
    "cropped_img_path = \"/data_vault/hexai/OAICartilage/image_manual_crops/9036771_20060321_10899612_slice_114.jpg\"  \n",
    "cropped_img = Image.open(cropped_img_path)\n",
    "print(f\"Cropped image dimensions: {cropped_img.size}\")\n",
    "\n",
    "\n",
    "cropped_annotation = \"/data_vault/hexai/OAICartilage/cropped_annotations/9036771_20060321_10899612/9036771_20060321_10899612_slice_114.nii.gz\"\n",
    "\n",
    "# Check if the file exists\n",
    "try:\n",
    "    # Load the NIfTI slice\n",
    "    cropped_annotation = nib.load(cropped_annotation)\n",
    "    cropped_annotation_slice_data = np.squeeze(cropped_annotation.get_fdata())  \n",
    "\n",
    "    # Print the dimensions of the annotation slice\n",
    "    print(f\"âœ… Cropped annotation slice dimensions: {cropped_annotation_slice_data.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ  slice not found: {cropped_annotation_slice_data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44e0af6-6b2c-4394-abd2-4683a00147db",
   "metadata": {},
   "source": [
    "## VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80a679-d31d-4368-8ae0-13c4806133e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nifti_path = \"/data_vault/hexai/OAICartilage/cropped_annotations/9021195_20050531_10534714/9021195_20050531_10534714_slice_036.nii.gz\"\n",
    "\n",
    "\n",
    "image = sitk.ReadImage(nifti_path)\n",
    "image_np = sitk.GetArrayFromImage(image)  # Expected shape: (1, height, width)\n",
    "\n",
    "print(f\"NIfTI shape: {image_np.shape}\")\n",
    "\n",
    "\n",
    "if image_np.shape[0] == 1:\n",
    "    image_np = image_np[0, :, :]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image_np, cmap=\"gray\")\n",
    "plt.title(\"Cropped Annotation Slice\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac391a3-212d-4ae2-973b-747ff619a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "study_id = \"9283264_20040722_10282013\"\n",
    "slice_num = \"060\"\n",
    "\n",
    "cropped_image_path = f\"/data_vault/hexai/OAICartilage/image_manual_crops/{study_id}_slice_{slice_num}.jpg\"\n",
    "cropped_annotation_path = f\"/data_vault/hexai/OAICartilage/cropped_annotations/{study_id}/{study_id}_slice_{slice_num}.nii.gz\"\n",
    "\n",
    "# Load cropped image\n",
    "img = Image.open(cropped_image_path).convert(\"RGB\")\n",
    "img_np = np.array(img)\n",
    "\n",
    "# Load annotation and squeeze to 2D\n",
    "annotation = sitk.ReadImage(cropped_annotation_path)\n",
    "annotation_np = sitk.GetArrayFromImage(annotation)\n",
    "\n",
    "if annotation_np.ndim == 3 and annotation_np.shape[0] == 1:\n",
    "    annotation_np = annotation_np[0, :, :]  # Convert to 2D\n",
    "\n",
    "\n",
    "label_colors = {\n",
    "    1: [0, 255, 0],      \n",
    "    2: [0, 0, 255],      \n",
    "    3: [255, 165, 0],    \n",
    "    4: [255, 0, 0],      \n",
    "}\n",
    "\n",
    "overlay = img_np.copy()\n",
    "\n",
    "for label, color in label_colors.items():\n",
    "    mask = annotation_np == label\n",
    "    for c in range(3):  # RGB channels\n",
    "        overlay[..., c][mask] = (0.6 * img_np[..., c][mask] + 0.4 * color[c]).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_np)\n",
    "plt.title(\"Original Cropped Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(annotation_np, cmap=\"gray\")\n",
    "plt.title(\"Annotation Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(overlay)\n",
    "plt.title(\"Overlay\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2698e2-2754-4f73-93f7-d4bc68626d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "study_id = \"9283264_20040722_10282013\"\n",
    "slice_num = \"060\"\n",
    "crop_idx = 0\n",
    "\n",
    "\n",
    "cropped_img_path = f\"/data_vault/hexai/OAICartilage/image_manual_crops/{study_id}_slice_{slice_num}.jpg\"\n",
    "cropped_annotation_path = f\"/data_vault/hexai/OAICartilage/cropped_annotations/{study_id}/{study_id}_slice_{slice_num}.nii.gz\"\n",
    "\n",
    "if not os.path.exists(cropped_img_path):\n",
    "    raise FileNotFoundError(f\"Image not found: {cropped_img_path}\")\n",
    "\n",
    "img = Image.open(cropped_img_path).convert(\"L\")\n",
    "img_np = np.array(img)\n",
    "print(f\"âœ… YOLO-cropped image shape (HÃ—W): {img_np.shape}\")\n",
    "\n",
    "\n",
    "if not os.path.exists(cropped_annotation_path):\n",
    "    raise FileNotFoundError(f\"Annotation not found: {cropped_annotation_path}\")\n",
    "\n",
    "annotation_nii = nib.load(cropped_annotation_path)\n",
    "annotation_data = np.squeeze(annotation_nii.get_fdata())\n",
    "print(f\"âœ… Cropped annotation shape (HÃ—W): {annotation_data.shape}\")\n",
    "\n",
    "\n",
    "if annotation_data.shape != img_np.shape:\n",
    "    print(\"Shape mismatch detected. Attempting transpose...\")\n",
    "    annotation_data = np.transpose(annotation_data, (1, 0))\n",
    "    print(f\"ðŸ” Transposed annotation shape: {annotation_data.shape}\")\n",
    "\n",
    "assert annotation_data.shape == img_np.shape, \"âŒ Shapes still don't match after transpose!\"\n",
    "\n",
    "\n",
    "overlay = np.zeros((img_np.shape[0], img_np.shape[1], 3), dtype=np.uint8)\n",
    "overlay[..., 0] = img_np  \n",
    "overlay[..., 1] = (annotation_data * 50).clip(0, 255).astype(np.uint8) \n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_np, cmap=\"gray\")\n",
    "plt.title(\"Cropped Image\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(annotation_data, cmap=\"gray\")\n",
    "plt.title(\"Cropped Annotation\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(overlay)\n",
    "plt.title(\"Overlay (Image + Mask)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6b906-225d-477f-9d16-f6fe1d37690c",
   "metadata": {},
   "source": [
    "## Renaming Cropped Annotations to match images (If needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf96fa8-3a2f-4325-99f1-84fe5b2d8cc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename Cropped Files\n",
    "cropped_annotations_folder = \"/data_vault/hexai/OAICartilage/cropped_annotations_simpleitk_v2\"\n",
    "\n",
    "# Iterate through each study ID folder\n",
    "for study_id in os.listdir(cropped_annotations_folder):\n",
    "    study_folder_path = os.path.join(cropped_annotations_folder, study_id)\n",
    "    \n",
    "    # Ensure it's a directory\n",
    "    if not os.path.isdir(study_folder_path):\n",
    "        continue\n",
    "\n",
    "    # Iterate through files in the study folder\n",
    "    for filename in os.listdir(study_folder_path):\n",
    "        if filename.endswith(\".nii.gz\") and \"_crop0\" in filename:\n",
    "            old_path = os.path.join(study_folder_path, filename)\n",
    "            new_filename = filename.replace(\"_crop0\", \"\")  # Remove \"_crop0\"\n",
    "            new_path = os.path.join(study_folder_path, new_filename)\n",
    "            \n",
    "            # Rename the file\n",
    "            os.rename(old_path, new_path)\n",
    "            print(f\"Renamed: {old_path} -> {new_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
